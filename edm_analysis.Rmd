---
title: "EDM Experimentation and Analysis"
author: "Eli Nimy"
date: '2022-07-18'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
# Open University Learning Analytics Dataset
library(oulad)

# Data Analyis and Visualisation
library(tidyverse)
```


## Student Virtual Learning Environment: Sum Clicks Analysis
- *code_module* – an identification code for a module.
- *code_presentation* - the identification code of the module presentation.
- *id_student* – a unique identification number for the student.
- *id_site* - an identification number for the VLE material.
- *date* – the date of student’s interaction with the material measured as the number of days since the start of the - module-presentation.
- *sum_click* – the number of times a student interacts with the material in that day.
```{r}
svle_df <- student_vle
svle_df
```


### Statistical Summary
```{r}
# Percentage of missing values
sum(is.na(svle_df$sum_click))/length(svle_df$sum_click) * 100
```



```{r}
# Sum of clicks statistical summary
svle_df$sum_click %>% summary()
```



```{r}
# Sum of clicks Standard deviation
round(sd(svle_df$sum_click),3)
```



```{r}
# Sum of clicks percentiles 
quantile(svle_df$sum_click, c(.25, .50, .75, .90, .95, .97, .99, .999, .9999, 1)) 
```


## Clustering 

```{r}
# Creating a dataframe consisting of only the Sum of clicks column 
sc_kmeans_df <- select(svle_df, sum_click)
sc_gmm_df <- select(svle_df, sum_click)
```



#### Data Scaling/Standardizing for K-means
- https://www.geeksforgeeks.org/normalization-vs-standardization/
```{r}
sc_kmeans_df <- scale(sc_kmeans_df)
sc_kmeans_df %>% head()
```


The use of set. seed is to make sure that we get the same results for randomization. If we randomly select some observations for any task in R or in any statistical software it results in different values all the time and this happens because of randomization.
```{r}
set.seed(123)
# Sys.setenv('R_MAX_VSIZE'=32000000000) 
# library(bigmemory)
# sc_df <- as.big.matrix(sc_df)
#memory.limit(8000)
#fviz_nbclust(sc_df[,], kmeans, method = "wss")
```



### K-means 
- Time Measurement included in algorithm execution
- https://www.r-bloggers.com/2017/05/5-ways-to-measure-running-time-of-r-code/
```{r}
# Clustering Algorithms 
library(cluster)
# Clustering Algorithms and Data Visualization
library(factoextra)
```


```{r}
# Fit K-means Model
start_time <- Sys.time()
kmeans_model <- kmeans(sc_kmeans_df, centers = 5, nstart = 25)
end_time <- Sys.time()
```


```{r}
print(kmeans_model)
```


### K-means Model Execution Time
```{r}
end_time - start_time
```


### GMM 
- Time Measurement included in algorithm execution
- https://www.r-bloggers.com/2017/05/5-ways-to-measure-running-time-of-r-code/
```{r}
# Gaussian mixture model (GMM)
library(mclust)
```


```{r}
 # Fit a GMM model
start_time <- Sys.time()
gmm_model <- Mclust(sc_t, G=5)
end_time <- Sys.time()
```


```{r}
print(gmm_model)
```


### GMM Model Execution Time
```{r}
end_time - start_time
```



```{r}
# Summary table 
summary(gmm_fit)
```



```{r}
# GMM Plot
plot(gmm_fit, 'BIC')
```



```{r}
# K-means clustering with subset of the dataset
kmeans_clust <- kmeans(head(sc_df, 10000), centers = 9, nstart = 25)
```



```{r}
# GMM clustering with subset of the dataset
gmm_clust <- Mclust(head(sc_t, 10000), 9) 
```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```



```{r}

```


